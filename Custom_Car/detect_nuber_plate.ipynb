{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from NumberPlate_OCR import ocr\n",
    "from yolov3.utils import detect_image, detect_realtime, detect_video, Load_Yolo_model, detect_video_realtime_mp\n",
    "from yolov3.configs import *\n",
    "from yolov3.yolov4 import Create_Yolo\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x25a7a1a8b08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo.load_weights(\"./checkpoints/yolov4_custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path   = \"./IMAGES/9.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-52oirelq\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9be94bd6f3ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m bb = detect_image(yolo, image_path, \"./IMAGES/plate_1_detect.jpg\", \n\u001b[1;32m----> 2\u001b[1;33m              input_size=YOLO_INPUT_SIZE, show=True, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Major\\Custom_Car\\yolov3\\utils.py\u001b[0m in \u001b[0;36mdetect_image\u001b[1;34m(Yolo, image_path, output_path, input_size, show, CLASSES, score_threshold, iou_threshold, rectangle_colors)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdetect_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYolo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m416\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mYOLO_COCO_CLASSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrectangle_colors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0moriginal_image\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m     \u001b[0moriginal_image\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[0moriginal_image\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-52oirelq\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "bb = detect_image(yolo, image_path, \"./IMAGES/plate_1_detect.jpg\", \n",
    "             input_size=YOLO_INPUT_SIZE, show=True, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.79700911,  10.78493118, 282.24310303, 166.1799469 ,\n",
       "          0.88488376,   0.        ])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-953eaae56921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnumber_plate_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m img = cv2.rectangle(img, (int(bb[0]),int(bb[1])), \n\u001b[0;32m      4\u001b[0m                                     (int(bb[0]+slot[2]),int(bb[1]+bb[3])), (255, 0, 0), )\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(image_path)\n",
    "number_plate_img = img[int(bb[1]):int(bb[3]),int(bb[0]):int(bb[2])]\n",
    "img = cv2.rectangle(img, (int(bb[0]),int(bb[1])), \n",
    "                                    (int(bb[0]+slot[2]),int(bb[1]+bb[3])), (255, 0, 0), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"qwe\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"cropped.png\",number_plate_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MH20DV2366'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr(\"cropped.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MH20DV2366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "path = \"cropped.png\"\n",
    "\n",
    "img_name = \"KA67PN9942.png\"\n",
    "\n",
    "filename = \"cropped.png\"\n",
    "\n",
    "gray = cv2.imread(filename, 0)\n",
    "gray = cv2.resize( gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "ocr(\"cropped.png\")\n",
    "\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "gray = cv2.medianBlur(gray, 3)\n",
    "# perform otsu thresh (using binary inverse since opencv contours work better with white text)\n",
    "ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "# cv2.imshow(\"Otsu\", thresh)\n",
    "cv2.waitKey(0)\n",
    "rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "\n",
    " \n",
    "dilation = cv2.dilate(thresh, rect_kern, iterations = 1)\n",
    "\n",
    "try:\n",
    "    contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "except:\n",
    "    ret_img, contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "sorted_contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "# create copy of image\n",
    "im2 = gray.copy()\n",
    "\n",
    "plate_num = \"\"\n",
    "# loop through contours and find letters in license plate\n",
    "for cnt in sorted_contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    height, width = im2.shape\n",
    "    \n",
    "    # if height of box is not a quarter of total height then skip\n",
    "    if height / float(h) > 6: continue\n",
    "    ratio = h / float(w)\n",
    "    # if height to width ratio is less than 1.5 skip\n",
    "    if ratio < 1.5: continue\n",
    "    area = h * w\n",
    "    # if width is not more than 25 pixels skip\n",
    "    if width / float(w) > 15: continue\n",
    "    # if area is less than 100 pixels skip\n",
    "    if area < 100: continue\n",
    "    # draw the rectangle\n",
    "    rect = cv2.rectangle(im2, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "    roi = thresh[y-5:y+h+5, x-5:x+w+5]\n",
    "    roi = cv2.bitwise_not(roi)\n",
    "    roi = cv2.medianBlur(roi, 5)\n",
    "    #cv2.imshow(\"ROI\", roi)\n",
    "    #cv2.waitKey(0)\n",
    "    text = pytesseract.image_to_string(roi, config='-c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ --psm 8 --oem 3')\n",
    "    #print(text)\n",
    "    plate_num += text\n",
    "print(ocr(\"cropped.png\"))\n",
    "# cv2.imshow(\"Character's Segmented\", im2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
